{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "00a85d4b-480f-4a84-a5c1-ec37e320b503",
    "_uuid": "4bce071d-67a6-4a39-a15b-46d47b4ea9b3"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices('GPU') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "af4a6227-5df1-49b9-aab5-239b307d954d",
    "_uuid": "43344a91-c191-445a-944a-621988e75290"
   },
   "outputs": [],
   "source": [
    "image_size=(54,128)\n",
    "def savepickle(fname,*args):\n",
    "    with open(fname+\"_pk\",\"wb\") as f:\n",
    "        pickle.dump(args,f)\n",
    "        \n",
    "def loadpickle(fname):\n",
    "    with open(fname,\"rb\") as f:\n",
    "        obj = pickle.load(f)\n",
    "        \n",
    "    return obj\n",
    "\n",
    "def reformat(x):\n",
    "    \"\"\"\n",
    "    input: x = array([[array([5.]), 1])\n",
    "    output: x = array([5,0,0,0,0])\n",
    "    \"\"\"\n",
    "    x = list(x[0])\n",
    "    #只截取5个，因为模型只输出5个\n",
    "    x = x[:5]\n",
    "    p = len(x)\n",
    "    x = x + [0]*(5-p)\n",
    "    return np.array(x)\n",
    "\n",
    "def load_data(rootdir,pk=\"digitStruct.mat_pk\",num_only=True):\n",
    "    #pk_path = os.path.join(rootdir,pk)\n",
    "    image_names,labels = loadpickle(pk)\n",
    "    \n",
    "    labels_x_len = labels[:,-1:] \n",
    "    labels_x_len[labels_x_len>5]=6\n",
    "    labels_x_len = labels_x_len.astype(float)\n",
    "    labels_num = np.apply_along_axis(reformat,1,labels)\n",
    "    labels = np.concatenate((labels_x_len,labels_num),axis=1)\n",
    "    image_names = np.array([os.path.join(rootdir,x) for x in image_names])\n",
    "    if num_only:\n",
    "        return image_names,labels_num\n",
    "\n",
    "    return image_names,labels\n",
    "\n",
    "def to_df(x,y):\n",
    "    xdf = pd.DataFrame(x,columns=[\"filename\"])\n",
    "    #这样有问题，应该 dataset = pd.DataFrame({'Column1': data[:, 0], 'Column2': data[:, 1]})\n",
    "    ydf = pd.DataFrame(y,columns=[\"len\",\"1\",\"2\",\"3\",\"4\",\"5\"])\n",
    "    ydf = ydf.astype(int)\n",
    "    \n",
    "    return pd.concat([xdf,ydf],axis=1)\n",
    "\n",
    "def to_one_hot(n_arr,cls_num):\n",
    "    onehot = np.zeros((n_arr.shape[1],cls_num))\n",
    "    onehot[np.arange(n_arr.shape[1]),n_arr]=1\n",
    "    return onehot\n",
    "\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, image_size)\n",
    "    image /= 255.0  # normalize to [0,1] range\n",
    "    image -= tf.math.reduce_mean(image,keepdims=True)\n",
    "    return image\n",
    "\n",
    "def load_and_preprocess_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    return preprocess_image(image)\n",
    "\n",
    "def datset_gen(images,lables,batch_size=16,buffer_size=1000):\n",
    "\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    path_ds = tf.data.Dataset.from_tensor_slices(images)\n",
    "    image_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
    "    label_ds = tf.data.Dataset.from_tensor_slices(lables)\n",
    "    img_lab_ds = tf.data.Dataset.zip((image_ds, label_ds))\n",
    "\n",
    "    return img_lab_ds.shuffle(buffer_size=buffer_size).repeat().batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plt_images(x,ylab=None,is_path=True,num=8):\n",
    "    indices = np.arange(x.shape[0])\n",
    "    n=1\n",
    "    for i in np.random.choice(indices,num):\n",
    "        plt.subplot(4,4,n)\n",
    "        img = x[i]\n",
    "        if is_path:\n",
    "            img = tf.io.read_file(img)\n",
    "            img = tf.image.decode_jpeg(img, channels=3)\n",
    "         \n",
    "        plt.imshow(img)\n",
    "        #plt.axis(\"off\")\n",
    "        n+=2\n",
    "        if ylab is not None:\n",
    "            yl = str(ylab[i])\n",
    "            xs = str(img.shape)\n",
    "            plt.text(0,-10,\"\".join((yl,xs)),ha=\"left\", va=\"bottom\", size=\"medium\",color=\"red\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from functools import partial\n",
    "import numpy as np \n",
    "from tensorflow.keras.layers import Flatten,Dense,Activation,MaxPool2D,GlobalAvgPool2D,BatchNormalization\n",
    "from tensorflow.keras.layers import Input,Conv2D,Lambda,Dropout\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "\n",
    "DefaultConv2D = partial(keras.layers.Conv2D, kernel_size=3, strides=1,kernel_initializer='random_uniform',\n",
    "                        padding=\"SAME\", use_bias=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "77df92b0-e5e0-4748-b576-dd38fd1cdbd1",
    "_uuid": "7d0e3a2f-5a92-42e7-8753-d7124860e01b"
   },
   "outputs": [],
   "source": [
    "def test_cnn(input_):\n",
    "    #image_in_vision = Input(shape=(image_size[0],image_size[1],3))\n",
    "    x = BatchNormalization()(input_)\n",
    "    for filter in [32]*2+[64]*1+[128]*1 :\n",
    "        x = DefaultConv2D(filter, strides=2, activation='relu')(x)\n",
    "        #x = BatchNormalization()(x)\n",
    "        x = DefaultConv2D(filter, strides=1, activation='relu')(x)\n",
    "        #x = BatchNormalization()(x)\n",
    "        x = Dropout(0.2)(x)\n",
    "        x = MaxPool2D(pool_size=(2,2), padding=\"SAME\")(x)\n",
    "   \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    #x = BatchNormalization()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    #h = BatchNormalization()(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def svhn_model_simple(input_shape=[54,128,3],N=5,class_num=11):\n",
    "    X=Input(shape=input_shape)\n",
    "    y = test_cnn(X)\n",
    "    #y = Dense(192,activation=\"relu\",kernel_initializer='he_normal')(y)\n",
    "    #y = Dense(512,activation=\"relu\",kernel_initializer='he_normal')(y)\n",
    "    #S = [ Dense(class_num,activation=\"softmax\",kernel_initializer='he_normal',name=\"cls_\".join(str(n)))(y) for n in range(N) ]\n",
    "    S = []\n",
    "    for n in range(N):\n",
    "        sn = Dense(512,activation=\"relu\",kernel_initializer='he_normal')(y)\n",
    "        sn = Dense(512,activation=\"relu\",kernel_initializer='he_normal')(sn)\n",
    "        sn = Dense(class_num,activation=\"softmax\",kernel_initializer='he_normal',name=\"cls_\".join(str(n)))(sn)\n",
    "        S.append(sn)\n",
    "    S = tf.stack(S,axis=1)\n",
    "    #S = Dense(N+2,activation=\"softmax\",kernel_initializer='he_normal')(y)\n",
    "    return Model(inputs=X,outputs=S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b18c2be2-a8c7-432e-8237-c9a00bf1e82c",
    "_uuid": "dd3a8be7-effd-491f-974e-5a911b6ba7bb"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "190f4337-e736-43a2-86a8-ede993f56743",
    "_uuid": "9a9addbc-cf1d-46a3-a716-3d83681d4ec8"
   },
   "outputs": [],
   "source": [
    "root_path = \"../../Coursera/Dl_ON_ud/dataset\"\n",
    "train_path =root_path+\"/train/digitStruct.mat_pk\"\n",
    "test_path =  root_path+\"/test/digitStruct.mat_pk\"\n",
    "extra_path = root_path+\"/extra/digitStruct.mat_pk\"\n",
    "is_num_only=True\n",
    "\n",
    "X_train,y_train = load_data(root_path+\"/train/\",train_path,num_only=is_num_only)\n",
    "X_test,y_test = load_data(root_path+\"/test/\",test_path,num_only=is_num_only)\n",
    "X_extra,y_extra = load_data(root_path+\"/extra/\",extra_path,num_only=is_num_only)\n",
    "\n",
    "X_train = np.concatenate([X_train,X_extra])\n",
    "y_train = np.concatenate([y_train,y_extra])\n",
    "y_train = y_train.reshape((-1,5,1))\n",
    "y_test = y_test.reshape((-1,5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "98baecc8-37e3-4e14-9207-200d6d65c791",
    "_uuid": "c5ae45b8-2362-482e-95c4-34d62ff3e9a8"
   },
   "outputs": [],
   "source": [
    "batch_size  = 64\n",
    "ds_train = datset_gen(X_train,y_train,batch_size=batch_size,buffer_size=10000)\n",
    "ds_test = datset_gen(X_test,y_test,batch_size=batch_size,buffer_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(235755,) (235755, 5, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x,y in ds_train.take(1):\n",
    "#     plt_images(x,y,False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "# model = svhn_train(ds_train,\n",
    "#                num_epochs=100,\n",
    "#                learning_rate=0.01,\n",
    "#                input_shape=[32,32,3],\n",
    "#                CNNModel=ResNet34,\n",
    "#                N=5,class_num=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "ebe39496-b283-4e06-8eb2-3c4f98d8d50e",
    "_uuid": "cff1bd51-24b1-4144-b8d6-56c45fa0ba86"
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(8,8))\n",
    "# for n, image in enumerate(ds_train.take(1)):\n",
    "#   plt.subplot(2,2,n+1)\n",
    "#   plt.imshow(image)\n",
    "#   plt.grid(False)\n",
    "#   plt.xticks([])\n",
    "#   plt.yticks([])\n",
    "#   plt.xlabel(caption_image(all_image_paths[n]))\n",
    "#   plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "008652fd-2c63-4a5c-8fcd-6e7494c2cb17",
    "_uuid": "c3646de6-96cb-4e34-92c5-c2498ebd8196"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "5986ea17-4ba9-480f-bb65-20bcf5c19edd",
    "_uuid": "ef3d113a-2072-4dce-8423-7d5200d2cf86"
   },
   "outputs": [],
   "source": [
    "\n",
    "#tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "#checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath=\"checkpoint_\"+model_save_file, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "fb5242b6-c193-4f15-ae84-35db5bf52857",
    "_uuid": "43983914-208e-487c-b9e5-e0f4bb47de00"
   },
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "5a3fc25f-2383-4900-8880-1c8c42fff7e0",
    "_uuid": "6f25534f-4f74-489b-884c-45ed273aa39d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3683/3683 [==============================] - 429s 116ms/step - loss: 1.9920 - accuracy: 0.5511 - val_loss: 1.9044 - val_accuracy: 0.6387\n",
      "Epoch 2/50\n",
      "3683/3683 [==============================] - 428s 116ms/step - loss: 1.9918 - accuracy: 0.5513 - val_loss: 1.9052 - val_accuracy: 0.6379\n",
      "Epoch 3/50\n",
      "3683/3683 [==============================] - 431s 117ms/step - loss: 1.9918 - accuracy: 0.5513 - val_loss: 1.9049 - val_accuracy: 0.6382\n",
      "Epoch 4/50\n",
      "  24/3683 [..............................] - ETA: 13:47 - loss: 1.9402 - accuracy: 0.6029"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-bbcb8b4da3fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epoches\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mds_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 validation_steps=100)#,callbacks=[lr_cb])\n\u001b[0m",
      "\u001b[1;32mI:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1297\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32mI:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mI:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[0;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[0;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[0;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[1;32mI:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mI:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[0;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[0;32m    312\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mI:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[1;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[0;32m    266\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backwards\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaled_total_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m           \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaled_total_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    269\u001b[0m           if isinstance(model.optimizer,\n\u001b[0;32m    270\u001b[0m                         loss_scale_optimizer.LossScaleOptimizer):\n",
      "\u001b[1;32mI:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1012\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mI:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[1;32mI:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mI:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py\u001b[0m in \u001b[0;36m_MulGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1167\u001b[0m     if skip_input_indices is not None and 1 in skip_input_indices and _IsScalar(\n\u001b[0;32m   1168\u001b[0m         y):\n\u001b[1;32m-> 1169\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1170\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m     \u001b[1;31m# No gradient skipping, so do the full gradient computation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mI:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   6683\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[0;32m   6684\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Mul\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6685\u001b[1;33m         name, _ctx._post_execution_callbacks, x, y)\n\u001b[0m\u001b[0;32m   6686\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6687\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_cce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model = svhn_model_simple(input_shape=[54,128,3])\n",
    "#optimizer = tf.keras.optimizers.Adamax(learning_rate=0.05,clipvalue=1)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# - 该模型5个位置，分别计算LOSS\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss_cce,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "num_epoches=50\n",
    "def scheduler(epoch):\n",
    "    if epoch < 5:\n",
    "        return 5.0\n",
    "    if epoch < 10:\n",
    "        return 0.5\n",
    "    return 0.05 * tf.math.exp(0.1 * (10 - epoch))\n",
    "\n",
    "lr_cb = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "with tf.device(\"/GPU:0\"):\n",
    "    history = model.fit_generator(ds_train,\n",
    "                steps_per_epoch=X_train.shape[0]//batch_size,\n",
    "                epochs=num_epoches,\n",
    "                validation_data=ds_test,\n",
    "                validation_steps=100)#,callbacks=[lr_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "620865d8-3c32-4ec1-a069-ce763a658666",
    "_uuid": "a06bc9fd-497b-4815-b67c-2a91c83b19bb"
   },
   "outputs": [],
   "source": [
    "weights = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6a725be4-b4ae-4e83-9310-ac855efbbd9c",
    "_uuid": "b2d2d6e2-0b2f-4e2a-a8e8-e85ecba85718"
   },
   "outputs": [],
   "source": [
    "model.save(\"model.cnnorg.h5\")\n",
    "savepickle(\"weitgh_only.h5\",weights)\n",
    "\n",
    "#-- visualize --\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import matplotlib as mpl\n",
    "#mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "#mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(num_epoches)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "\n",
    "# class LossHistory(keras.callbacks.Callback):\n",
    "#     def on_train_begin(self, logs={}):\n",
    "#         self.losses = []\n",
    "\n",
    "#     def on_batch_end(self, batch, logs={}):\n",
    "#         self.losses.append(logs.get('loss'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
