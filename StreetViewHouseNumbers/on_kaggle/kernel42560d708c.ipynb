{"cells":[{"metadata":{"_uuid":"4bce071d-67a6-4a39-a15b-46d47b4ea9b3","_cell_guid":"00a85d4b-480f-4a84-a5c1-ec37e320b503","trusted":true},"cell_type":"code","source":"import collections\nimport pickle\n\nimport os\nimport numpy as np\nimport pandas as pd\n\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.config.experimental.list_physical_devices('GPU') ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Utils"},{"metadata":{"_uuid":"43344a91-c191-445a-944a-621988e75290","_cell_guid":"af4a6227-5df1-49b9-aab5-239b307d954d","trusted":true},"cell_type":"code","source":"image_size=(128,128)\ndef savepickle(fname,*args):\n    with open(fname+\"_pk\",\"wb\") as f:\n        pickle.dump(args,f)\n        \ndef loadpickle(fname):\n    with open(fname,\"rb\") as f:\n        obj = pickle.load(f)\n        \n    return obj\n\ndef reformat(x):\n    \"\"\"\n    input: x = array([[array([5.]), 1])\n    output: x = array([5,0,0,0,0])\n    \"\"\"\n    x = list(x[0])\n    #只截取5个，因为模型只输出5个\n    x = x[:5]\n    p = len(x)\n    x = x + [0]*(5-p)\n    return np.array(x)\n\ndef load_data(rootdir,pk=\"digitStruct.mat_pk\",num_only=True):\n    #pk_path = os.path.join(rootdir,pk)\n    image_names,labels = loadpickle(pk)\n    \n    labels_x_len = labels[:,-1:] \n    labels_x_len[labels_x_len>5]=6\n    labels_x_len = labels_x_len.astype(float)\n    labels_num = np.apply_along_axis(reformat,1,labels)\n    labels = np.concatenate((labels_x_len,labels_num),axis=1)\n    image_names = np.array([os.path.join(rootdir,x) for x in image_names])\n    if num_only:\n        return image_names,labels_num\n\n    return image_names,labels\n\ndef to_df(x,y):\n    xdf = pd.DataFrame(x,columns=[\"filename\"])\n    #这样有问题，应该 dataset = pd.DataFrame({'Column1': data[:, 0], 'Column2': data[:, 1]})\n    ydf = pd.DataFrame(y,columns=[\"len\",\"1\",\"2\",\"3\",\"4\",\"5\"])\n    ydf = ydf.astype(int)\n    \n    return pd.concat([xdf,ydf],axis=1)\n\ndef to_one_hot(n_arr,cls_num):\n    onehot = np.zeros((n_arr.shape[1],cls_num))\n    onehot[np.arange(n_arr.shape[1]),n_arr]=1\n    return onehot\n\n\ndef preprocess_image(image):\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.image.resize(image, image_size)\n    image /= 255.0  # normalize to [0,1] range\n    return image\n\ndef load_and_preprocess_image(path):\n    image = tf.io.read_file(path)\n    return preprocess_image(image)\n\ndef datset_gen(images,lables,batch_size=16,buffer_size=1000):\n\n    AUTOTUNE = tf.data.experimental.AUTOTUNE\n    path_ds = tf.data.Dataset.from_tensor_slices(images)\n    image_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n    label_ds = tf.data.Dataset.from_tensor_slices(lables)\n    img_lab_ds = tf.data.Dataset.zip((image_ds, label_ds))\n\n    return img_lab_ds.shuffle(buffer_size=buffer_size).repeat().batch(batch_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plt_images(x,ylab=None,is_path=True,num=8):\n    indices = np.arange(x.shape[0])\n    n=1\n    for i in np.random.choice(indices,num):\n        plt.subplot(4,4,n)\n        img = x[i]\n        if is_path:\n            img = tf.io.read_file(img)\n            img = tf.image.decode_jpeg(img, channels=3)\n         \n        plt.imshow(img)\n        #plt.axis(\"off\")\n        n+=2\n        if ylab is not None:\n            yl = str(ylab[i])\n            xs = str(img.shape)\n            plt.text(0,-10,\"\".join((yl,xs)),ha=\"left\", va=\"bottom\", size=\"medium\",color=\"red\")\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom functools import partial\nimport numpy as np \nfrom tensorflow.keras.layers import Flatten,Dense,Activation,MaxPool2D,GlobalAvgPool2D,BatchNormalization\nfrom tensorflow.keras.layers import Input,Conv2D,Lambda,Dropout\nfrom tensorflow.keras import Model\n\n\nDefaultConv2D = partial(keras.layers.Conv2D, kernel_size=3, strides=1,kernel_initializer='random_uniform',\n                        padding=\"SAME\", use_bias=False)\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7d0e3a2f-5a92-42e7-8753-d7124860e01b","_cell_guid":"77df92b0-e5e0-4748-b576-dd38fd1cdbd1","trusted":true},"cell_type":"code","source":"def CNN_org(input):\n    #image_in_vision = Input(shape=(image_size[0],image_size[1],3))\n    x = BatchNormalization(axis=3)(input)\n    x = Convolution2D(32, 3, 3, activation='tanh')(x)\n    x = BatchNormalization(axis=3)(x)\n    x = Convolution2D(32, 3, 3, activation='relu')(x)\n    x = BatchNormalization(axis=3)(x)\n    x = Dropout(0.2)(x)\n    x = MaxPooling2D(pool_size=(2,2))(x)\n    x = Convolution2D(64, 3, 3, activation='relu')(x)\n    x = BatchNormalization(axis=3)(x)\n    x = Convolution2D(64, 3, 3, activation='relu')(x)\n    x = BatchNormalization(axis=3)(x)\n    x = Dropout(0.2)(x)\n    x = MaxPooling2D(pool_size=(2,2))(x)\n    x = Convolution2D(128, 3, 3, activation='relu')(x)\n    x = BatchNormalization(axis=3)(x)\n    x = Convolution2D(128, 3, 3, activation='relu')(x)\n    x = BatchNormalization(axis=3)(x)\n    x = Dropout(0.2)(x)\n    x = MaxPooling2D(pool_size=(2,2))(x)\n    x = Flatten()(x)\n    x = Dense(1024, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dense(1024, activation='relu')(x)\n    h = BatchNormalization()(x)\n    return Model(input=image_in_vision, output=h, name='vision')\n\ndef svhn_model_simple(input_shape=[128,128,3],N=5,class_num=11):\n    X=Input(shape=input_shape)\n    y = CNN_org(X)\n    y = Dense(20,activation=\"relu\",kernel_initializer='random_uniform')(y)\n    S = [ Dense(class_num,activation=\"softmax\",kernel_initializer='random_uniform')(y) for _ in range(N) ]\n    S = tf.stack(S,axis=1)\n    #S = Dense(N+2,activation=\"softmax\",kernel_initializer='he_normal')(y)\n    return Model(inputs=X,outputs=S)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dd3a8be7-effd-491f-974e-5a911b6ba7bb","_cell_guid":"b18c2be2-a8c7-432e-8237-c9a00bf1e82c","trusted":true},"cell_type":"markdown","source":"## Train"},{"metadata":{"_uuid":"9a9addbc-cf1d-46a3-a716-3d83681d4ec8","_cell_guid":"190f4337-e736-43a2-86a8-ede993f56743","trusted":true},"cell_type":"code","source":"root_path = \"/kaggle/input/street-view-house-numbers/\"\ntrain_path =\"/kaggle/input/svhnpk/train_digitStruct.mat_pk\"\ntest_path =  \"/kaggle/input/svhnpk/test_digitStruct.mat_pk\"\nextra_path = \"/kaggle/input/svhnpk/extra_digitStruct.mat_pk\"\nis_num_only=True\nX_test,y_test = load_data(root_path+\"test/test/\",test_path,num_only=is_num_only)\nX_train,y_train = load_data(root_path+\"train/train/\",train_path,num_only=is_num_only)\nX_extra,y_extra = load_data(root_path+\"extra/extra/\",extra_path,num_only=is_num_only)\n\nX_train = np.concatenate([X_train,X_extra])\ny_train = np.concatenate([y_train,y_extra])\ny_train = y_train.reshape((-1,5,1))\ny_test = y_test.reshape((-1,5,1))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c5ae45b8-2362-482e-95c4-34d62ff3e9a8","_cell_guid":"98baecc8-37e3-4e14-9207-200d6d65c791","trusted":true},"cell_type":"code","source":"batch_size  = 64\nds_train = datset_gen(X_train,y_train,batch_size=batch_size,buffer_size=100)\nds_test = datset_gen(X_test,y_test,batch_size=batch_size,buffer_size=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape,y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for x,y in ds_train.take(1):\n    plt_images(x,y,False)\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"# model = svhn_train(ds_train,\n#                num_epochs=100,\n#                learning_rate=0.01,\n#                input_shape=[32,32,3],\n#                CNNModel=ResNet34,\n#                N=5,class_num=11)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cff1bd51-24b1-4144-b8d6-56c45fa0ba86","_cell_guid":"ebe39496-b283-4e06-8eb2-3c4f98d8d50e","trusted":true},"cell_type":"code","source":"# import matplotlib.pyplot as plt\n\n# plt.figure(figsize=(8,8))\n# for n, image in enumerate(ds_train.take(1)):\n#   plt.subplot(2,2,n+1)\n#   plt.imshow(image)\n#   plt.grid(False)\n#   plt.xticks([])\n#   plt.yticks([])\n#   plt.xlabel(caption_image(all_image_paths[n]))\n#   plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c3646de6-96cb-4e34-92c5-c2498ebd8196","_cell_guid":"008652fd-2c63-4a5c-8fcd-6e7494c2cb17","trusted":true},"cell_type":"code","source":"loss_cce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\nmodel = svhn_model_simple(input_shape=[32,32,3])\noptimizer = tf.keras.optimizers.SGD(learning_rate=0.1,clipvalue=1)\n\n# - 该模型5个位置，分别计算LOSS\nmodel.compile(optimizer=optimizer,\n              loss=loss_cce,\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ef3d113a-2072-4dce-8423-7d5200d2cf86","_cell_guid":"5986ea17-4ba9-480f-bb65-20bcf5c19edd","trusted":true},"cell_type":"code","source":"\n#tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n#checkpoint_cb = keras.callbacks.ModelCheckpoint(filepath=\"checkpoint_\"+model_save_file, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"43983914-208e-487c-b9e5-e0f4bb47de00","_cell_guid":"fb5242b6-c193-4f15-ae84-35db5bf52857","trusted":true},"cell_type":"code","source":"#model.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6f25534f-4f74-489b-884c-45ed273aa39d","_cell_guid":"5a3fc25f-2383-4900-8880-1c8c42fff7e0","trusted":true},"cell_type":"code","source":"num_epoches=100\nmodel_save_file=\"temp.h5\"\nwith tf.device(\"/GPU:0\"):\n    history = model.fit_generator(ds_train,\n                steps_per_epoch=X_train.shape[0]//batch_size,\n                epochs=num_epoches,\n                validation_data=ds_test,\n                validation_steps=100)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a06bc9fd-497b-4815-b67c-2a91c83b19bb","_cell_guid":"620865d8-3c32-4ec1-a069-ce763a658666","trusted":true},"cell_type":"code","source":"weights = model.get_weights()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weights","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b2d2d6e2-0b2f-4e2a-a8e8-e85ecba85718","_cell_guid":"6a725be4-b4ae-4e83-9310-ac855efbbd9c","trusted":true},"cell_type":"code","source":"model.save(\"model.cnnorg.h5\")\nsavepickle(\"weitgh_only.h5\",weights)\n\n#-- visualize --\nimport matplotlib.pyplot as plt\n\n#import matplotlib as mpl\n#mpl.rcParams['figure.figsize'] = (8, 6)\n#mpl.rcParams['axes.grid'] = False\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(num_epoches)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()\n\n# class LossHistory(keras.callbacks.Callback):\n#     def on_train_begin(self, logs={}):\n#         self.losses = []\n\n#     def on_batch_end(self, batch, logs={}):\n#         self.losses.append(logs.get('loss'))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}